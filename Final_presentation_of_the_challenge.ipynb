{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\asent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import random\n",
    "import time\n",
    "import itertools\n",
    "import cv2 as cv\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#TO COMPLETE \n",
    "original_path = \"\"\n",
    "imgPath     = original_path + \"TRAINING/\"\n",
    "##########################################################################\n",
    "\n",
    "model_path = 'modelV85.h5'\n",
    "\n",
    "IMAGE_SIZE = 180\n",
    "colored = True\n",
    "img_channels = 3 if colored else 1\n",
    "\n",
    "if original_path==\"\":\n",
    "  raise Exception(\"you should complete the original_path\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\asent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\asent\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "The model contain  707473  parameters\n",
      "Size of the model is : 8.17 MB\n"
     ]
    }
   ],
   "source": [
    "# model_path = 'model.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "total_params = model.count_params()\n",
    "print(\"The model contain \",total_params, \" parameters\")\n",
    "\n",
    "\n",
    "# Get the size in MB\n",
    "size_model = os.path.getsize(model_path)/ (1024*1024)  \n",
    "print(f\"Size of the model is : {size_model:.2f} MB\")\n",
    "\n",
    "# # Summary to check total params and ensure it's under 1 million\n",
    "# my_FRmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHALL_AGC_ComputeRecognScores(auto_ids, true_ids):\n",
    "    #   Compute face recognition score\n",
    "    #\n",
    "    #   INPUTS\n",
    "    #     - AutomSTR: The results of the automatic face\n",
    "    #     recognition algorithm, stored as an integer\n",
    "    #\n",
    "    #     - AGC_Challenge_STR: The ground truth ids\n",
    "    #\n",
    "    #   OUTPUT\n",
    "    #     - FR_score:     The final recognition score\n",
    "    #\n",
    "    #   --------------------------------------------------------------------\n",
    "    #   AGC Challenge\n",
    "    #   Universitat Pompeu Fabra\n",
    "    #\n",
    "\n",
    "    if len(auto_ids) != len(true_ids):\n",
    "        assert ('Inputs must be of the same len');\n",
    "\n",
    "    f_beta = 1\n",
    "    res_list = list(filter(lambda x: true_ids[x] != -1, range(len(true_ids))))\n",
    "\n",
    "    nTP = len([i for i in res_list if auto_ids[i] == true_ids[i]])\n",
    "\n",
    "    res_list = list(filter(lambda x: auto_ids[x] != -1, range(len(auto_ids))))\n",
    "\n",
    "    nFP = len([i for i in res_list if auto_ids[i] != true_ids[i]])\n",
    "\n",
    "    res_list_auto_ids = list(filter(lambda x: auto_ids[x] == -1, range(len(auto_ids))))\n",
    "    res_list_true_ids = list(filter(lambda x: true_ids[x] != -1, range(len(true_ids))))\n",
    "\n",
    "    nFN = len(set(res_list_auto_ids).intersection(res_list_true_ids))\n",
    "\n",
    "    FR_score = (1 + f_beta ** 2) * nTP / ((1 + f_beta ** 2) * nTP + f_beta ** 2 * nFN + nFP)\n",
    "\n",
    "    return FR_score,nTP,res_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Face detection\n",
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "\n",
    "#parameter for the detection\n",
    "scaleFactor  = 1.05\n",
    "minNeighbors = 6\n",
    "minsize      = 100\n",
    "# maxsize      = 700\n",
    "\n",
    "#I have to change the minsize for new images because they are \n",
    "def MyFaceDetectionFunction(img): #from lab 1\n",
    "    frame_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv.equalizeHist(frame_gray)\n",
    "\n",
    "    #-- Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        frame_gray, \n",
    "        scaleFactor  = scaleFactor, \n",
    "        minNeighbors = minNeighbors, \n",
    "        minSize      = (minsize, minsize),\n",
    "        # maxSize      = (maxsize, maxsize)\n",
    "    )\n",
    "    return faces\n",
    "\n",
    "def select_two_biggest_faces(faces):\n",
    "    areas = []\n",
    "    M =[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        x1 = x\n",
    "        y1 = y\n",
    "        x2 = x1 + w \n",
    "        y2 = y1 + h\n",
    "        M.append([x1,y1,x2,y2])\n",
    "        areas.append(w*h)\n",
    "        \n",
    "    if len(M)>2:\n",
    "        first_face = 0\n",
    "        second_face = 1\n",
    "        if areas[first_face]<areas[second_face]: #check if the biggest face is on index 2, then swap index\n",
    "            first_face, second_face = 1, 0\n",
    "        for j in range(2,len(M)):\n",
    "            if areas[j]>areas[first_face]:\n",
    "                second_face = first_face\n",
    "                first_face  = j\n",
    "            elif areas[j]> areas[second_face]:\n",
    "                second_face = j\n",
    "        M = [M[first_face],M[second_face]]\n",
    "    return M\n",
    "  \n",
    "#Preprocessing of the Data\n",
    "def process_image(img):\n",
    "    img_resized = cv.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "    if not colored:\n",
    "        grey_img = cv.cvtColor(img_resized, cv.COLOR_BGR2GRAY)\n",
    "        face_normalized = grey_img /255.0\n",
    "        face = np.expand_dims(face_normalized, axis=-1) \n",
    "        return face\n",
    "\n",
    "    else:\n",
    "        colored_img = cv.cvtColor(img_resized, cv.COLOR_BGR2RGB)\n",
    "        face_normalized = colored_img /255.0\n",
    "\n",
    "        return face_normalized\n",
    "    \n",
    "def crop_and_normalize_image(img,faces):\n",
    "    cropped_and_normalized_faces =[]\n",
    "    for (x1, y1, x2, y2) in faces:\n",
    "            face = img[y1:y2, x1:x2]\n",
    "            processed_image = process_image(face)\n",
    "            cropped_and_normalized_faces.append(processed_image)\n",
    "            # cv.imwrite(Saving_folder + im, img_resized)\n",
    "    return cropped_and_normalized_faces\n",
    "\n",
    "def detect_crop_and_normalize_image(img):\n",
    "    # We apply face detection\n",
    "    facesDetected = MyFaceDetectionFunction(img)\n",
    "    cropped_and_normalized_faces=[]\n",
    "    # We select the two biggest faces\n",
    "    faces = select_two_biggest_faces(facesDetected)    \n",
    "    have_a_face = len(faces)>0\n",
    "    # Save_detection(img,faces,im)\n",
    "    if have_a_face:\n",
    "        #-- Handle images with detected faces\n",
    "        have_a_face = True\n",
    "        # Crop, normalize, and collect faces if detected\n",
    "        cropped_and_normalized_faces = crop_and_normalize_image(img,faces)\n",
    "    return cropped_and_normalized_faces,have_a_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "    cropped_and_normalized_faces,have_a_face = detect_crop_and_normalize_image(image)\n",
    "  \n",
    "    if not have_a_face:\n",
    "        return -1\n",
    "    \n",
    "    best_prediction = 0\n",
    "    class_ = 0\n",
    "    \n",
    "    for face in cropped_and_normalized_faces:\n",
    "        face_batch = np.expand_dims(face, axis=0)  # format the model to (1, 224, 224, 1)\n",
    "        predictions = model.predict(face_batch,verbose=0)\n",
    "        \n",
    "        predicted_class = np.argmax(predictions, axis=1)\n",
    "        val_prediction = np.max(predictions[0])\n",
    "        \n",
    "        if  val_prediction>best_prediction:\n",
    "            best_prediction = predicted_class[0]\n",
    "            class_ = predicted_class[0]\n",
    "    if class_ ==0: \n",
    "        return -1\n",
    "    else:\n",
    "        return class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 85.22, Total time:  1 m 32.02 s\n"
     ]
    }
   ],
   "source": [
    "# Basic script for Face Recognition Challenge\n",
    "# --------------------------------------------------------------------\n",
    "# AGC Challenge\n",
    "# Universitat Pompeu Fabra\n",
    "\n",
    "# Load challenge Training data\n",
    "dir_challenge3 = original_path\n",
    "AGC_Challenge3_TRAINING = loadmat(dir_challenge3 + \"AGC_Challenge3_Training.mat\")\n",
    "AGC_Challenge3_TRAINING = np.squeeze(AGC_Challenge3_TRAINING['AGC_Challenge3_TRAINING'])\n",
    "\n",
    "imageName = AGC_Challenge3_TRAINING['imageName']\n",
    "imageName = list(itertools.chain.from_iterable(imageName))\n",
    "\n",
    "ids = list(AGC_Challenge3_TRAINING['id'])\n",
    "ids = np.concatenate(ids).ravel().tolist()\n",
    "\n",
    "faceBox = AGC_Challenge3_TRAINING['faceBox']\n",
    "faceBox = list(itertools.chain.from_iterable(faceBox))\n",
    "    \n",
    "\n",
    "# Initialize results structure\n",
    "AutoRecognSTR = []\n",
    "\n",
    "# Initialize timer accumulator\n",
    "total_time = 0\n",
    "\n",
    "# Load your FRModel\n",
    "my_FRmodel = model\n",
    "\n",
    "for idx, im in enumerate(imageName):\n",
    "\n",
    "    image = cv.imread(imgPath + im)\n",
    "        \n",
    "\n",
    "    try:\n",
    "        print(f\"Image number : {idx}\", end='\\r')  \n",
    "        ti = time.time()\n",
    "        # Timer on\n",
    "        ###############################################################\n",
    "        # Your face recognition function goes here.It must accept 2 input parameters:\n",
    "\n",
    "        # 1. the input image A\n",
    "        # 2. the recognition model\n",
    "\n",
    "        # and must return a single integer number as output, which can be:\n",
    "\n",
    "        # a) A number between 1 and 80 (representing one of the identities in the training set)\n",
    "        # b) A \"-1\" indicating that none of the 80 users is present in the input image\n",
    "        \n",
    "        autom_id = predict(my_FRmodel,image)\n",
    "        tt = time.time() - ti\n",
    "        total_time = total_time + tt\n",
    "    except:\n",
    "        # If the face recognition function fails, it will be assumed that no user was detected for his input image\n",
    "        autom_id = random.randint(-1, 80)\n",
    "\n",
    "    AutoRecognSTR.append(autom_id)\n",
    "\n",
    "FR_score ,nTP, res_list= CHALL_AGC_ComputeRecognScores(AutoRecognSTR, ids)\n",
    "_, rem = divmod(total_time, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print('F1-score: %.2f, Total time: %2d m %.2f s' % (100 * FR_score, int(minutes), seconds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
